{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## Dataset\n",
    "\n",
    "In this set of exercises we will use the same dataset as from [week 3](week_3.ipynb). \n",
    "\n",
    "\n",
    "As before, we provide the data already curated in the following two files:\n",
    "\n",
    "`RNA_expression_curated.csv`: [148 cell lines , 238 genes]\n",
    "\n",
    "`drug_response_curated.csv`: [148 cell lines , YM155 drug]\n",
    "\n",
    "The curated data can be read as `pandas` `DataFrame` in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gene_expression = pd.read_csv(\"./data/RNA_expression_curated.csv\", sep=',', header=0, index_col=0)\n",
    "drug_response = pd.read_csv(\"./data/drug_response_curated.csv\", sep=',', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the exercises is to train support vector machine (SVM) and random forests classifiers on this dataset and explore and learn about their hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The `scikit-learn` library provides the required tools for support vector machines, as well as for random forest algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_circles\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, look up the documentation of the imported functions and read about their basic functionality. Below, we list some important parameters of SVMs and random forests that can be tuned during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)\n",
    "\n",
    "`C`: error term.\n",
    "\n",
    "`kernel`: similarity function ('linear', 'poly', 'sigmoid' or 'rbf')\n",
    "\n",
    "`gamma`: kernel coef. for 'rbf', 'poly' and 'sigmoid' kernels. It can be thought of as the ‘spread’ of the kernel and therefore the decision region.\n",
    "\n",
    "`degree`: degree for the 'poly' kernel.\n",
    "\n",
    "`coef0`: independt term in the 'poly' and 'sigmoid' kernels\n",
    "\n",
    "\n",
    "#### Random Forests\n",
    "\n",
    "`n_estimators`: number of trees in our random forest.\n",
    "\n",
    "`max_depth`: maximum number of levels in each decision tree\n",
    "\n",
    "`max_features`: maximum number of features to consider per split in an individual tree.\n",
    "\n",
    "`min_sample_leaf`: minimum number of data points per leaf node\n",
    "\n",
    "`min_samples_split`: minimum number of data points placed in a node before the node is split\n",
    "\n",
    "`oob_score`: the out-of-bag (OOB) error is the average error for each observation calculated using predictions from the trees that do not contain that observation in their respective bootstrap sample. Set this parameter to true.\n",
    "\n",
    "`bootstrap`: method for sampling data points (with or without replacement). Set this parameter to true.\n",
    "\n",
    "`criterion`: function used to measure the quality of the split (e.g. 'entropy' or 'gini')\n",
    "\n",
    "# Exercises\n",
    "\n",
    "## Support vector machines\n",
    "\n",
    "The  `make_blobs` and `make_circles` functions can be used to generate linearly and not linearly separable toy datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation: linearly separable\n",
    "X, Y = make_blobs(n_samples=200, centers=2, n_features=2, random_state=1234)\n",
    "X = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code illustrates how to train a linear SVM classifier and plot the data points, the separating hyperplane, the support vectors and the margins that pass through them (considering the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# build the model\n",
    "model = svm.SVC(kernel='linear', random_state=33)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# get colors from qualitative colormap 'Paired'\n",
    "cmap = plt.cm.get_cmap('Paired')\n",
    "\n",
    "# plot data points\n",
    "ax.scatter(X_train.iloc[Y_train == 1, 0], X_train.iloc[Y_train == 1, 1],\n",
    "           c=[cmap(11)], label='1')\n",
    "ax.scatter(X_train.iloc[Y_train == 0, 0], X_train.iloc[Y_train == 0, 1],\n",
    "           c=[cmap(0)], label='0')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "# plot the decision function\n",
    "# create grid to evaluate model\n",
    "x1_min, x1_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
    "x2_min, x2_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
    "\n",
    "XX, YY = np.meshgrid(np.arange(x1_min, x1_max, .2),\n",
    "                     np.arange(x2_min, x2_max, .2))\n",
    "\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "           linestyles=['--', '-', '--'])\n",
    "\n",
    "# Establish the class for each point in the contour\n",
    "Z = model.predict(xy).reshape(XX.shape)\n",
    "\n",
    "# Visualization of the contour\n",
    "ax.contourf(XX, YY, Z, cmap='bwr', alpha=0.3)\n",
    "\n",
    "# plot support vectors, whose are responsible for building the margins\n",
    "ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k', marker='s')\n",
    "\n",
    "ax.axis([x1_min, x1_max, x2_min, x2_max])\n",
    "plt.axis('tight')\n",
    "plt.title('Linear kernel SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a radial basis function (RBF) SVM classifier with `gamma=0.5` and plot the results in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation: not linearly separable\n",
    "X, Y = make_circles(n_samples=200, noise=0.05, random_state=1234)\n",
    "X = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><font color='#770a0a'>When should a RBF kernel be used over a linear kernel? Motivate your answer.</font></p>\n",
    "\n",
    "<p><font color='#770a0a'>Do we need to normalize the data before using a kernel function? Motivate your answer.\n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting drug response on cell lines from gene expression data with SVMs\n",
    "\n",
    "Explore the hyper-parameter space of an SVM classifier with cross-validation for the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. The`GridSearchCV` function can be used to specify a grid of parameter values with the `param_grid` parameter.\n",
    "\n",
    "Calculate the precision of your predictions, and compare your calculations with the results of `classification_report`, which displays many classification metrics.\n",
    "\n",
    "\n",
    "## Random forests\n",
    "\n",
    "Follow the same steps as for SVM. Compare the two algorithms and report which one has better performance.\n",
    "\n",
    "The random forests classifiers allows to perform feature selection. Evaluate the importance of features extracting the top 50 informative features. A bar plot (`plt.bar()`) can be a useful tool to visualize this. \n",
    "\n",
    "\n",
    "## Biomedical applications\n",
    "\n",
    "Driven by technological advances, there has recently been a dramatic increase in availability of biomedical data. Machine learning approaches are well suited to take advantage of this data and have been widely applied to many areas of biology. \n",
    "\n",
    "Example of these applications are genome annotation, biomarker identification, systems biology, genome data analysis, protein  function  prediction, protein  structure prediction, protein localization prediction, identification of protein interactions and drug discovery.\n",
    "\n",
    "SVM and RF methods are among the most popular machine learning methods applied in bioinformatics or computational biology.\n",
    "\n",
    "Perform a literature search and find a biomedical study in which SVM or RF is applied to obtain certain insights. <p><font color='#770a0a'>Explain the motivation behind using that specific algorithm in the study.\n",
    "</font></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
